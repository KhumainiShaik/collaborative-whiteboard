# Excalidraw + Yjs on Kubernetes - Complete Documentation

**Status:** âœ… Production Ready | **Updated:** December 2025 | **Cluster:** k3s (3 nodes, GCP)

## ğŸ“– Documentation Index

**START HERE** â†’ Choose based on your need:

| Document | Purpose | Read Time |
|----------|---------|-----------|
| **[README_MONITORING.md](./README_MONITORING.md)** â­ | Navigation hub for all docs | 2 min |
| **[FRESH_SETUP.md](./FRESH_SETUP.md)** | Deploy from scratch + debugging fixes | 15 min |
| **[OBSERVABILITY.md](./OBSERVABILITY.md)** | Monitoring architecture & metrics | 10 min |
| **[TASK4_DEMO.md](./TASK4_DEMO.md)** | Live demo walkthrough (HPA, Yjs, monitoring) | 12 min |
| **[FINAL_ARCHITECTURE.md](./FINAL_ARCHITECTURE.md)** | Complete system design & verification | 10 min |

---

## ğŸš€ Quick Access

### Application
- **Main App:** http://34.49.56.133
- **Grafana:** http://34.49.56.133/grafana (admin/admin)

### Cluster Commands
```bash
# Via GCP IAP tunnel
gcloud compute ssh private-cloud-server-0 --zone=us-central1-a --tunnel-through-iap

# View pods
sudo kubectl get pods -n whiteboard
sudo kubectl get pods -n monitoring

# View system resources
sudo kubectl top nodes
sudo kubectl top pods -n whiteboard
```

---

## ğŸ“š Documentation (Clean & Consolidated)

| Document | Purpose | Read Time |
|----------|---------|-----------|
| **[README_START_HERE.md](./README_START_HERE.md)** | Documentation index & quick reference | 3 min |
| **[FINAL_ARCHITECTURE.md](./FINAL_ARCHITECTURE.md)** | Complete system design & verification | 10 min |
| **[DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md)** | Manifest reference & deployment procedures | 15 min |
| **[MONITORING_DASHBOARD.md](./MONITORING_DASHBOARD.md)** | Grafana/Prometheus setup & access | 8 min |
| **[VIDEO_DEMO_COMMANDS.md](./VIDEO_DEMO_COMMANDS.md)** | Task 4 demonstration commands | 20 min |
| **[TROUBLESHOOTING.md](./TROUBLESHOOTING.md)** | Common issues & solutions | Reference |

---

## âœ… Task Requirements Status

### Task 3: Multi-Instance Deployment
âœ… **COMPLETE** - 7 containers (3 Excalidraw + 3 y-websocket + 1 Redis) across 2 worker nodes

**Verification:**
```bash
kubectl get pods -n whiteboard -o wide
# Shows pods distributed across private-cloud-worker-0 and private-cloud-worker-1
```

### Task 4 Gap 1: Monitoring & Observability
âœ… **COMPLETE** - Prometheus metrics collection + Grafana visualization

**Access:** http://34.49.56.133:31519 (admin/admin)

**Verification:**
```bash
kubectl get pods -n monitoring
# Shows: prometheus-* and grafana-* both Running
```

### Task 4 Gap 2: Horizontal Scaling
âœ… **COMPLETE** - HPA configured (Excalidraw 2-8, y-websocket 1-4 replicas)

**Verification:**
```bash
kubectl get hpa -n whiteboard  # Shows HPA configuration
kubectl get deployment -n whiteboard -o custom-columns=NAME:.metadata.name,DESIRED:.spec.replicas,READY:.status.readyReplicas
```

### Task 4 Gap 4: Resource Visibility
âœ… **COMPLETE** - Metrics Server + kubectl top + Prometheus/Grafana

**Verification:**
```bash
kubectl top nodes        # Node CPU/memory
kubectl top pods -n whiteboard  # Pod CPU/memory
```

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GCP HTTP Load Balancer (External)  â”‚
â”‚  34.49.56.133:80 â†’ NGINX Ingress    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  k3s Kubernetes Cluster (3 nodes)   â”‚
â”‚                                     â”‚
â”‚  whiteboard namespace:              â”‚
â”‚  â€¢ Excalidraw UI (3 replicas)       â”‚
â”‚  â€¢ y-websocket (3 replicas)         â”‚
â”‚  â€¢ Redis (1 replica)                â”‚
â”‚                                     â”‚
â”‚  monitoring namespace:              â”‚
â”‚  â€¢ Prometheus (metrics)             â”‚
â”‚  â€¢ Grafana (dashboards)             â”‚
â”‚                                     â”‚
â”‚  kube-system namespace:             â”‚
â”‚  â€¢ Metrics Server (resource API)    â”‚
â”‚  â€¢ CoreDNS, nginx-ingress           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Nodes:**
- `private-cloud-server-0` (4 CPU, 8 GB, Control Plane)
- `private-cloud-worker-0` (4 CPU, 8 GB, App pods)
- `private-cloud-worker-1` (4 CPU, 8 GB, App pods)

---

## ğŸ” Key Metrics (Baseline)

| Component | CPU | Memory | Status |
|-----------|-----|--------|--------|
| Each Node | 1-2% | 7-11% | âœ… Low utilization |
| Excalidraw UI (per pod) | 2-3m | 18-21 Mi | âœ… Stable |
| y-websocket (per pod) | 1-2m | 12-14 Mi | âœ… Stable |
| Redis | 1m | 11 Mi | âœ… Stable |

---

## ğŸ“¦ Kubernetes Manifests

All manifests in `k8s-manifests/` directory (32 total resources):

| File | Type | Count | Status |
|------|------|-------|--------|
| 00-namespace.yaml | Namespace | 1 | âœ… |
| 01-mongodb-secret.yaml | Secret | 1 | âœ… |
| 03-redis-statefulset.yaml | StatefulSet | 1 | âœ… |
| 05-yjs-deployment.yaml | Deployment + Service | 2 | âœ… |
| 06-excalidraw-deployment.yaml | Deployment + Service | 2 | âœ… |
| 07-network-policy.yaml | NetworkPolicy | 1 | âœ… |
| 08-ingress-tls.yaml | Ingress | 1 | âœ… |
| 09-excalidraw-nginx-config.yaml | ConfigMap | 1 | âœ… |
| 10-snapshot-cronjob.yaml | CronJob | 1 | âœ… |
| 11-nginx-ingress.yaml | Ingress | 1 | âœ… |
| 12-prometheus.yaml | Monitoring (6 resources) | 6 | âœ… |
| 13-grafana.yaml | Monitoring (3 resources) | 3 | âœ… |
| 14-hpa.yaml | HPA (2 autoscalers) | 2 | âœ… |
| 15-metrics-server.yaml | System (7 resources) | 7 | âœ… |

---

## ğŸ¯ For Video Demonstration

**See:** [VIDEO_DEMO_COMMANDS.md](./VIDEO_DEMO_COMMANDS.md)

**Segments (14 min total):**
1. Architecture & Task Requirements (2 min)
2. Task 3 - Multi-Instance Verification (1 min)
3. Gap 1 - Monitoring Dashboard (3 min)
4. Gap 4 - Resource Visibility (2 min)
5. Gap 2 - Scaling Configuration (4 min)
6. Final System Health Check (1 min)

**Pre-Demo Checklist:**
```bash
# Run 5 minutes before recording
kubectl get pods -n whiteboard
kubectl get pods -n monitoring
kubectl get hpa -n whiteboard
kubectl top nodes
```

---

## ğŸ› ï¸ Commands Reference

### System Status
```bash
kubectl get ns | grep -E 'whiteboard|monitoring'
kubectl get pods -A --no-headers | wc -l
kubectl get nodes -o wide
```

### Application
```bash
kubectl get deployment -n whiteboard -o custom-columns=NAME:.metadata.name,REPLICAS:.spec.replicas,READY:.status.readyReplicas
kubectl top pods -n whiteboard
```

### Monitoring
```bash
kubectl get pods -n monitoring
kubectl get svc -n monitoring
# Grafana: http://34.49.56.133:31519 (admin/admin)
```

### Scaling
```bash
kubectl get hpa -n whiteboard
kubectl describe hpa excalidraw-ui-hpa -n whiteboard
```

### Load Test
```bash
cd /path/to/scripts
python load-test.py  # Generates 5 concurrent users
# Watch scaling: kubectl get hpa -w
```

---

## ğŸ“– Documentation Files

For **Deployment:** See [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md)  
For **Monitoring Setup:** See [MONITORING_DASHBOARD.md](./MONITORING_DASHBOARD.md)  
For **Architecture Details:** See [FINAL_ARCHITECTURE.md](./FINAL_ARCHITECTURE.md)  
For **Issues:** See [TROUBLESHOOTING.md](./TROUBLESHOOTING.md)

---

## ğŸŒ Access Points

| Service | URL | Credentials | Purpose |
|---------|-----|-------------|---------|
| Excalidraw App | http://34.49.56.133 | None | Main application |
| Grafana | http://34.49.56.133:31519 | admin/admin | Monitoring dashboard |
| Prometheus | See MONITORING_DASHBOARD.md | None | Metrics query |
| Kubernetes API | Via IAP tunnel | kubeconfig | Admin access |

---

## For Academic Evaluation

1. **System Design:** [FINAL_ARCHITECTURE.md](./FINAL_ARCHITECTURE.md) - Section "Architecture Overview"
2. **Task Verification:** [README_START_HERE.md](./README_START_HERE.md) - Section "Task Requirements Verification"
3. **Deployment:** [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md) - Full deployment process documented
4. **Monitoring:** [MONITORING_DASHBOARD.md](./MONITORING_DASHBOARD.md) - All metrics and observability
5. **Testing:** [VIDEO_DEMO_COMMANDS.md](./VIDEO_DEMO_COMMANDS.md) - Reproducible test commands

---

## Quick Problem Solving

**Pod not starting?**
```bash
kubectl describe pod <pod-name> -n whiteboard
kubectl logs <pod-name> -n whiteboard
```

**Metrics not showing?**
```bash
kubectl get pods -n kube-system -l k8s-app=metrics-server
kubectl logs -n kube-system -l k8s-app=metrics-server
```

**Grafana dashboard blank?**
```bash
kubectl port-forward -n monitoring svc/prometheus 9090:9090
# Check http://localhost:9090/graph for metrics
```

See [TROUBLESHOOTING.md](./TROUBLESHOOTING.md) for more solutions.

---

## ğŸ“‹ System Status

- **Namespaces:** whiteboard, monitoring, kube-system âœ…
- **Pods Running:** 13 (7 application + 2 monitoring + 4 system) âœ…
- **Nodes:** 3 (all ready) âœ…
- **Services:** 2 (Excalidraw UI + yjs websocket, Grafana dashboard) âœ…
- **Monitoring:** Prometheus + Grafana âœ…
- **Metrics:** kubectl top working âœ…
- **Ingress:** NGINX ingress controller âœ…

**System is fully operational and ready for production use.**
2. **START_HERE_PRODUCTION.md** â€” See what's deployed
3. **PRODUCTION_QUICK_START.md** â€” Test the live app

### For DevOps Setup (15 min read)
1. **ARCHITECTURE.md** â€” System design
2. **NGINX_BRANCH_DEPLOYMENT.md** â€” How to deploy
3. **TROUBLESHOOTING.md** â€” How to fix issues

### For Technical Review (20 min read)
1. **ARCHITECTURE.md** â€” Components
2. **FIXES_AND_MIGRATION.md** â€” All fixes from Traefik â†’ NGINX (6 issues per phase)
3. **NGINX_BRANCH_DEPLOYMENT.md** â€” Deployment flow
4. **FIXES_APPLIED_SUMMARY.md** â€” Current GCS IAM fix details
5. **TROUBLESHOOTING.md** â€” How to maintain

---

## Quick Commands

### Check Deployment Status
```bash
gcloud compute ssh private-cloud-server-0 --zone=us-central1-a --tunnel-through-iap
sudo kubectl -n whiteboard get pods,svc -o wide
```

### View Application Logs
```bash
sudo kubectl -n whiteboard logs -l app=excalidraw-ui --tail=50
sudo kubectl -n whiteboard logs -l app=yjs-server --tail=50
```

### Verify Real-Time Sync
```bash
# Open 2 browser tabs:
# Tab 1: http://34.49.56.133/
# Tab 2: http://34.49.56.133/
# Draw on Tab 1 â†’ See instant sync on Tab 2
```

### Check Snapshot Export
```bash
sudo kubectl -n whiteboard get cronjob,jobs
gsutil ls gs://helical-sled-477919-e9-whiteboard-snapshots/
```

---

## Architecture at a Glance

```
Public IP (34.49.56.133)
         â†“
GCP HTTP Load Balancer
         â†“
Private VPC (Cloud NAT, Firewall)
         â†“
NGINX Ingress (NodePort 31853)
         â†“
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
    â†“    â†“    â†“
Excalidraw  yjs-ws  Redis
  (2x)     (1x)    (1x)
    â†“    â†“    â†“
    â””â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”˜
         â†“
   MongoDB Atlas â† Metadata
   GCS Bucket â† Snapshots
```

---

## Deployment Status

| Component | Status |
|-----------|--------|
| Excalidraw UI (2 replicas) | âœ… Running |
| y-websocket (1 replica) | âœ… Running |
| Redis (1 replica) | âœ… Running |
| NGINX Ingress Controller | âœ… Running |
| GCP Load Balancer | âœ… Healthy |
| MongoDB Atlas | âœ… Connected |
| GCS Snapshots | âœ… Operational |

**Overall:** PRODUCTION-READY âœ…

---

## Branches

### nginx-migration (CURRENT)
- NGINX Ingress (no Helm)
- Fixed y-websocket binding (0.0.0.0)
- GCS IAM fixed (roles/storage.objectAdmin)
- All components operational
- **6 fixes applied during migration (see FIXES_AND_MIGRATION.md)**
- **Use this branch for new deployments**

### master (REFERENCE)
- Earlier iteration with Traefik
- Useful for understanding evolution
- Compare with nginx-migration to see improvements
- **6 issues fixed during initial Traefik setup (documented in FIXES_AND_MIGRATION.md)**
- **Do not use for new deployments**

---

## Support

**For deployment issues:** See NGINX_BRANCH_DEPLOYMENT.md â†’ Troubleshooting section

**For general troubleshooting:** See TROUBLESHOOTING.md

**For architecture questions:** See ARCHITECTURE.md

---

**Ready for Submission:** âœ… YES

All manifests in `k8s-manifests/`, documentation complete, deployment operational.
